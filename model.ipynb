{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23041,"status":"ok","timestamp":1700119978444,"user":{"displayName":"Ta Rek","userId":"16525203218948016019"},"user_tz":-60},"id":"wEq2gidngX06","outputId":"ab582529-ac48-43e8-d231-45f08b2a9084"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7843,"status":"ok","timestamp":1700119991144,"user":{"displayName":"Ta Rek","userId":"16525203218948016019"},"user_tz":-60},"id":"H7_yLfDMgb1X","outputId":"1c1b34bc-e611-4e46-c230-1e6b4b73df90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 4048, done.\u001b[K\n","remote: Counting objects: 100% (4048/4048), done.\u001b[K\n","remote: Compressing objects: 100% (3076/3076), done.\u001b[K\n","remote: Total 4048 (delta 1185), reused 2794 (delta 914), pack-reused 0\u001b[K\n","Receiving objects: 100% (4048/4048), 54.69 MiB | 13.36 MiB/s, done.\n","Resolving deltas: 100% (1185/1185), done.\n"]}],"source":["!git clone --depth 1 https://github.com/tensorflow/models\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive\n","!ls /mydrive\n","%cd /content/gdrive/MyDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FRXgTtw-hrsm"},"outputs":[],"source":["%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zkHvTwBiROm"},"outputs":[],"source":["!pip install pyyaml==5.3\n","!pip install /content/gdrive/MyDrive/models/research/\n","!pip install tensorflow==2.11.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QiC96ubH0im3"},"outputs":[],"source":["import re\n","with open('/content/gdrive/MyDrive/models/research/object_detection/packages/tf2/setup.py') as f:\n","    s = f.read()\n","with open('/content/gdrive/MyDrive/models/research/setup.py', 'w') as f:\n","    # Set fine_tune_checkpoint path\n","    s = re.sub('tf-models-official>=2.5.1',\n","               'tf-models-official==2.8.0', s)\n","    f.write(s)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTUM-auDjQ7U"},"outputs":[],"source":["!python models/research/object_detection/builders/model_builder_tf2_test.py"]},{"cell_type":"markdown","source":["**Create CSV data files and TFRecord files**\n","\n","---\n","\n"],"metadata":{"id":"7_Gr89sOr2CR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpchHBKNMx7d"},"outputs":[],"source":["!python create_csv.py\n","!python3 create_tfrecord.py --csv_input=images/train_labels.csv --labelmap=labelmap.txt --image_dir=images/train --output_path=train.tfrecord\n","!python3 create_tfrecord.py --csv_input=images/validation_labels.csv --labelmap=labelmap.txt --image_dir=images/validation --output_path=val.tfrecord"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFKvtGJqM3KF"},"outputs":[],"source":["train_record_fname = '/content/gdrive/MyDrive/train.tfrecord'\n","val_record_fname = '/content/gdrive/MyDrive/val.tfrecord'\n","label_map_pbtxt_fname = '/content/gdrive/MyDrive/labelmap.pbtxt'"]},{"cell_type":"markdown","source":["Change the chosen_model variable to deploy different models available in the TF2 object detection zoo"],"metadata":{"id":"Xm4X4bcRsQix"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LaLJDykRM3Gz"},"outputs":[],"source":["chosen_model = 'efficientdet-d0'\n","\n","MODELS_CONFIG = {\n","    'ssd-mobilenet-v2': {\n","        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n","        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n","    },\n","    'efficientdet-d0': {\n","        'model_name': 'efficientdet_d0_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n","    },\n","    'ssd-mobilenet-v2-fpnlite-320': {\n","        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n","        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n","    },\n","}\n","\n","model_name = MODELS_CONFIG[chosen_model]['model_name']\n","pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n","base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q31Nkcs9sPAd"},"outputs":[],"source":["%mkdir /content/gdrive/MyDrive/models/mymodel/\n","%cd /content/gdrive/MyDrive/models/mymodel/\n","\n","# Download pre-trained model weights\n","import tarfile\n","download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n","!wget {download_tar}\n","tar = tarfile.open(pretrained_checkpoint)\n","tar.extractall()\n","tar.close()\n","\n","# Download training configuration file for model\n","download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n","!wget {download_config}"]},{"cell_type":"markdown","source":["Set training parameters for the model"],"metadata":{"id":"_tLPjN0PskfB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cd2Amyiescef"},"outputs":[],"source":["num_steps = 1500\n","\n","if chosen_model == 'efficientdet-d0':\n","  batch_size = 30\n","else:\n","  batch_size = 60"]},{"cell_type":"markdown","source":["Set file locations and get number of classes for config file"],"metadata":{"id":"m5RwFd7Xstqz"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":485,"status":"ok","timestamp":1700120524977,"user":{"displayName":"Ta Rek","userId":"16525203218948016019"},"user_tz":-60},"id":"i9UgS5YwsoP1","outputId":"e250db65-afdf-460f-83a9-a21804576644"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total classes: 1\n"]}],"source":["pipeline_fname = '/content/gdrive/MyDrive/models/mymodel/' + base_pipeline_file\n","fine_tune_checkpoint = '/content/gdrive/MyDrive/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n","\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","print('Total classes:', num_classes)"]},{"cell_type":"markdown","source":["Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file"],"metadata":{"id":"WqPAaThNs8V_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1309,"status":"ok","timestamp":1700120526280,"user":{"displayName":"Ta Rek","userId":"16525203218948016019"},"user_tz":-60},"id":"jYsHncLDssl5","outputId":"332a455a-169c-4620-ba64-fe788f03a2ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/models/mymodel\n","writing custom configuration file\n"]}],"source":["import re\n","\n","%cd /content/gdrive/MyDrive/models/mymodel\n","print('writing custom configuration file')\n","\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open('pipeline_file.config', 'w') as f:\n","\n","    # Set fine_tune_checkpoint path\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","\n","    # Set tfrecord files for train and test datasets\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n","\n","    # Set label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set batch_size\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","\n","    # Set number of classes num_classes\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","\n","    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n","    s = re.sub(\n","        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n","\n","    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n","    if chosen_model == 'ssd-mobilenet-v2':\n","      s = re.sub('learning_rate_base: .8',\n","                 'learning_rate_base: .08', s)\n","\n","      s = re.sub('warmup_learning_rate: 0.13333',\n","                 'warmup_learning_rate: .026666', s)\n","\n","    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n","    if chosen_model == 'efficientdet-d0':\n","      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n","      s = re.sub('pad_to_max_dimension: true', '', s)\n","      s = re.sub('min_dimension', 'height', s)\n","      s = re.sub('max_dimension', 'width', s)\n","\n","    f.write(s)\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"n4lLy6xutPih"}},{"cell_type":"markdown","source":["Set the path to the custom config file and the directory to store training checkpoints in\n"],"metadata":{"id":"du9A9iQftXwu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5ZUFWyhtMS3"},"outputs":[],"source":["# Set the path to the custom config file and the directory to store training checkpoints in\n","pipeline_file = '/content/gdrive/MyDrive/models/mymodel/pipeline_file.config'\n","model_dir = '/content/gdrive/MyDrive/training/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"im_dpoBStlWp"},"outputs":[],"source":["# Run training!\n","!python /content/gdrive/MyDrive/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1\n","print(\"Train Finish!!\")"]},{"cell_type":"markdown","source":["**Export inference graph**\n"],"metadata":{"id":"s7konZrUCHtZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8E5TTjpd0Cdd"},"outputs":[],"source":["!python /content/gdrive/MyDrive/models/research/object_detection/exporter_main_v2.py \\\n","    --trained_checkpoint_dir=/content/gdrive/MyDrive/training \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --output_directory /content/gdrive/MyDrive/training/inferance_graph"]},{"cell_type":"markdown","source":["**Loading the saved_model**\n"],"metadata":{"id":"e22QuYk1Ckts"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47375,"status":"ok","timestamp":1700120578540,"user":{"displayName":"Ta Rek","userId":"16525203218948016019"},"user_tz":-60},"id":"aPfePhFsg3L9","outputId":"2c564836-ba9d-43e0-80a3-e74046a94972"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model...Done!\n"]}],"source":["%matplotlib inline\n","import tensorflow as tf\n","import time\n","import os\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","IMAGE_SIZE = (12, 8) # Output display size as you want\n","import matplotlib.pyplot as plt\n","PATH_TO_SAVED_MODEL= \"/content/gdrive/MyDrive/training/inferance_graph/saved_model\"\n","print('Loading model...', end='')\n","\n","# Load saved model and build the detection function\n","detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","print('Done!')\n","\n","#Loading the label_map\n","category_index=label_map_util.create_category_index_from_labelmap(\"/content/gdrive/MyDrive/labelmap.pbtxt\",use_display_name=True)"]},{"cell_type":"markdown","source":["**only the desired bounding boxes are visualized and saved**"],"metadata":{"id":"VORktet9HF8b"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQ_Lg6cbh5TI"},"outputs":[],"source":["import numpy as np\n","import os\n","from PIL import Image\n","import tensorflow as tf\n","from object_detection.utils import visualization_utils as viz_utils\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","def load_image_into_numpy_array(path):\n","    return np.array(Image.open(path))\n","\n","# Set the path to the directory containing your test images\n","IMAGE_DIR = \"/content/gdrive/MyDrive/ALL_image/\"\n","\n","# Directory to save the bounding boxes\n","SAVE_DIR = \"/content/gdrive/MyDrive/BB_ALL_Images/\"\n","if not os.path.exists(SAVE_DIR):\n","    os.makedirs(SAVE_DIR)\n","\n","# Get all files from the directory\n","all_image_files = [f for f in os.listdir(IMAGE_DIR) if os.path.isfile(os.path.join(IMAGE_DIR, f))]\n","\n","# Iterate over each image\n","for image_file in all_image_files:\n","    image_path = os.path.join(IMAGE_DIR, image_file)\n","    print(f'Running inference for {image_path}...')\n","\n","    image_np = load_image_into_numpy_array(image_path)\n","\n","    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","    input_tensor = tf.convert_to_tensor(image_np)\n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis, ...]\n","\n","    detections = detect_fn(input_tensor)\n","\n","    # Convert batch tensors to numpy arrays and remove batch dimension\n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                  for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    image_np_with_detections = image_np.copy()\n","\n","    # Filter detections based on score and size\n","    valid_boxes = []\n","    valid_scores = []\n","    valid_classes = []\n","    for i, box in enumerate(detections['detection_boxes']):\n","        ymin, xmin, ymax, xmax = box\n","        width = (xmax - xmin) * image_np.shape[1]\n","        height = (ymax - ymin) * image_np.shape[0]\n","        if detections['detection_scores'][i] >= 0.999 and height > 51 and width > 34:\n","            valid_boxes.append(box)\n","            valid_scores.append(detections['detection_scores'][i])\n","            valid_classes.append(detections['detection_classes'][i])\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","        image_np_with_detections,\n","        np.array(valid_boxes),\n","        np.array(valid_classes).astype(np.int64),\n","        np.array(valid_scores),\n","        category_index,\n","        use_normalized_coordinates=True,\n","        max_boxes_to_draw=None,\n","        min_score_thresh=0.999, # This is redundant now but kept for clarity\n","        agnostic_mode=False)\n","\n","    saved_count = 0\n","    for i, box in enumerate(valid_boxes):\n","        (left, right, top, bottom) = (box[1] * image_np.shape[1], box[3] * image_np.shape[1],\n","                                      box[0] * image_np.shape[0], box[2] * image_np.shape[0])\n","        cropped_image = Image.fromarray(image_np[int(top):int(bottom), int(left):int(right)])\n","\n","        # Save the bounding box as a jpg file\n","        cropped_image_path = os.path.join(SAVE_DIR, f\"{os.path.splitext(image_file)[0]}_box_{i}.jpg\")\n","        cropped_image.save(cropped_image_path)\n","        print(f'Saved box {i} to {cropped_image_path}')\n","        saved_count += 1\n","\n","    print(f'Number of bounding boxes saved for {image_path}: {saved_count}')\n","\n","    # Plot the image with detections\n","    plt.figure(figsize=(12, 8))\n","    plt.axis(\"off\")\n","    plt.imshow(image_np_with_detections)\n","    plt.show()"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1rvijk76SvPy7H46TGohf5xKcQycpmF8J","authorship_tag":"ABX9TyMeRBr5jdhR6qnoxAAEmy2e"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}